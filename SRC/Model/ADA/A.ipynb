{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e829b2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ec4afa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_est_A = pd.read_csv('train_est_A.csv')\n",
    "df_train_obs_A = pd.read_csv('train_obs_A.csv')\n",
    "df_test_A = pd.read_csv('X_test_A.csv')\n",
    "df_train_est_A = df_train_est_A.rename(columns={'Unnamed: 0': 'date_forecast'})\n",
    "\n",
    "df_train_obs_A = df_train_obs_A.rename(columns={'Unnamed: 0': 'date_forecast'})\n",
    "\n",
    "df_test_A = df_test_A.rename(columns={'Unnamed: 0': 'date_forecast'})\n",
    "\n",
    "df_train_est_A.set_index('date_forecast', inplace=True)\n",
    "df_train_obs_A.set_index('date_forecast', inplace=True)\n",
    "df_test_A.set_index('date_forecast', inplace=True)\n",
    "df_train_obs_A.index = pd.to_datetime(df_train_obs_A.index)\n",
    "df_train_obs_A.index = pd.to_datetime(df_train_obs_A.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6ace265e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_est_A=df_train_est_A.drop(columns=['date_calc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f3af2bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df_train_obs_A,df_train_est_A])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "79203632",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "df = df.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))\n",
    "df_test_A = df_test_A.rename(columns = lambda x:re.sub('[^A-Za-z0-9_]+', '', x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "043f2294",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.index = pd.to_datetime(df.index)\n",
    "df['hours'] = df.index.hour\n",
    "df['day'] = df.index.day\n",
    "df['month'] = df.index.month\n",
    "df['year'] = df.index.year\n",
    "df_test_A.index = pd.to_datetime(df_test_A.index)\n",
    "df_test_A['hours'] = df_test_A.index.hour\n",
    "df_test_A['day'] = df_test_A.index.day\n",
    "df_test_A['month'] = df_test_A.index.month\n",
    "df_test_A['year'] = df_test_A.index.year\n",
    "df_test_A = df_test_A.drop(columns = 'date_calc', axis = 1)\n",
    "df['dayofyear'] = df.index.day_of_year\n",
    "df_test_A['dayofyear'] = df_test_A.index.day_of_year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0922e90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5)\n",
    "# Imputa i valori mancanti\n",
    "df_knn =pd.DataFrame(imputer.fit_transform(df),columns = df.columns, index = df.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ebb28a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = df.drop(columns = 'pv_measurement').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab34e956",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Crea un oggetto MinMaaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "# Normalizza il DataFrame\n",
    "df_normalized = pd.DataFrame(scaler.fit_transform(df_knn[columns]),columns = df_knn[columns].columns, index = df_knn[columns].index)\n",
    "df_normalized['pv_measurement'] = df[ 'pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1856dc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "# Sample DataFrame (replace this with your own dataset)\n",
    "data = df_normalized\n",
    "# Define the number of splits (e.g., 5 for 80-20 train-test splits)\n",
    "n_splits = 3\n",
    "# Initialize the TimeSeriesSplit\n",
    "tscv = TimeSeriesSplit(n_splits=n_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc59abc9-2568-418c-abc8-077814c3f5b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di Feature usate:  1\n",
      "MAE medio :  355.1316092250611\n",
      "Numero di Feature usate:  2\n",
      "MAE medio :  283.86386923412846\n",
      "Numero di Feature usate:  3\n",
      "MAE medio :  303.00809024703227\n",
      "Numero di Feature usate:  4\n",
      "MAE medio :  278.9881896953671\n",
      "Numero di Feature usate:  5\n",
      "MAE medio :  278.7411140655558\n",
      "Numero di Feature usate:  6\n",
      "MAE medio :  279.4061718130589\n",
      "Numero di Feature usate:  7\n",
      "MAE medio :  300.8209772685974\n",
      "Numero di Feature usate:  8\n",
      "MAE medio :  292.00713881601405\n",
      "Numero di Feature usate:  9\n",
      "MAE medio :  293.6600676382466\n",
      "Numero di Feature usate:  10\n",
      "MAE medio :  284.2322074194553\n",
      "Numero di Feature usate:  11\n",
      "MAE medio :  299.3908840918212\n",
      "Numero di Feature usate:  12\n",
      "MAE medio :  302.8905895828467\n",
      "Numero di Feature usate:  13\n",
      "MAE medio :  303.44276430809487\n",
      "Numero di Feature usate:  14\n",
      "MAE medio :  296.891971737543\n",
      "Numero di Feature usate:  15\n",
      "MAE medio :  288.06933559530546\n",
      "Numero di Feature usate:  16\n",
      "MAE medio :  330.57395057021535\n",
      "Numero di Feature usate:  17\n",
      "MAE medio :  330.4275853478287\n",
      "Numero di Feature usate:  18\n",
      "MAE medio :  296.0589766560528\n",
      "Numero di Feature usate:  19\n",
      "MAE medio :  360.26895118850814\n",
      "Numero di Feature usate:  20\n",
      "MAE medio :  319.0848875259378\n",
      "Numero di Feature usate:  21\n",
      "MAE medio :  358.70434440341495\n",
      "Numero di Feature usate:  22\n",
      "MAE medio :  324.30164288090765\n",
      "Numero di Feature usate:  23\n",
      "MAE medio :  340.6666565969648\n",
      "Numero di Feature usate:  24\n",
      "MAE medio :  306.4394832291491\n",
      "Numero di Feature usate:  25\n",
      "MAE medio :  298.05585084904567\n",
      "Numero di Feature usate:  26\n",
      "MAE medio :  345.65811374902165\n",
      "Numero di Feature usate:  27\n",
      "MAE medio :  314.3215970841219\n",
      "Numero di Feature usate:  28\n",
      "MAE medio :  338.9318214856842\n",
      "Numero di Feature usate:  29\n",
      "MAE medio :  293.09199843143546\n",
      "Numero di Feature usate:  30\n",
      "MAE medio :  333.35227504130074\n",
      "Numero di Feature usate:  31\n",
      "MAE medio :  335.7408027921121\n",
      "Numero di Feature usate:  32\n",
      "MAE medio :  390.9992368799093\n",
      "Numero di Feature usate:  33\n",
      "MAE medio :  342.7918559818457\n",
      "Numero di Feature usate:  34\n",
      "MAE medio :  355.8315010912148\n",
      "Numero di Feature usate:  35\n",
      "MAE medio :  353.8292932466602\n",
      "Numero di Feature usate:  36\n",
      "MAE medio :  374.9625436837073\n",
      "Numero di Feature usate:  37\n",
      "MAE medio :  344.6043270869012\n",
      "Numero di Feature usate:  38\n",
      "MAE medio :  344.810294997087\n",
      "Numero di Feature usate:  39\n",
      "MAE medio :  333.8903342347706\n",
      "Numero di Feature usate:  40\n",
      "MAE medio :  359.33143576189985\n",
      "Numero di Feature usate:  41\n",
      "MAE medio :  311.034967367209\n",
      "Numero di Feature usate:  42\n",
      "MAE medio :  355.8503165730549\n",
      "Numero di Feature usate:  43\n",
      "MAE medio :  351.3810847772029\n",
      "Numero di Feature usate:  44\n",
      "MAE medio :  340.23039948119947\n",
      "Numero di Feature usate:  45\n",
      "MAE medio :  317.72041158909616\n",
      "Numero di Feature usate:  46\n",
      "MAE medio :  287.70244885978667\n",
      "Numero di Feature usate:  47\n",
      "MAE medio :  321.9352915823478\n",
      "Numero di Feature usate:  48\n",
      "MAE medio :  371.1610934375327\n",
      "Numero di Feature usate:  49\n",
      "MAE medio :  340.18277182127196\n",
      "Numero di Feature usate:  50\n",
      "MAE medio :  306.282672025992\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import AdaBoostRegressor\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "# Definisci il modello di machine learning\n",
    "model = AdaBoostRegressor()\n",
    "\n",
    "# Definisci il selezionatore di feature\n",
    "rfe = RFE(estimator=model, n_features_to_select=None)\n",
    "\n",
    "# Trova il numero migliore di feature in base al MAE\n",
    "errors = []\n",
    "for n_features in range(1, len(df.columns)):\n",
    "    rfe.n_features_to_select = n_features\n",
    "    print(\"Numero di Feature usate: \",n_features)\n",
    "    # Calcola il MAE utilizzando la cross-validation\n",
    "    maelist = []\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        train_data = data.iloc[train_index]\n",
    "        test_data = data.iloc[test_index]\n",
    "\n",
    "        # Extract target variable for training and testing data\n",
    "        y_train = train_data['pv_measurement']\n",
    "        y_test = test_data['pv_measurement']\n",
    "\n",
    "        # Extract features for training and testing data\n",
    "        X_train = train_data.drop(columns = 'pv_measurement')\n",
    "        X_test = test_data.drop(columns = 'pv_measurement')\n",
    "        \n",
    "        # Train the XGBoost model\n",
    "        rfe.fit(X_train, y_train)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = rfe.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        maelist.append(mae)\n",
    "    # Calcola il MAE medio\n",
    "    mean_mae = np.mean(maelist)\n",
    "    print(\"MAE medio : \",mae)\n",
    "    errors.append(mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "51e34b1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_index = errors.index(min(errors))\n",
    "errros_df = pd.DataFrame(errors)\n",
    "n_features = min_index + 1\n",
    "n_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3365261a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rfe.support_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "127c0baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = df_normalized[selected_features]\n",
    "data['pv_measurement'] = df_knn[\"pv_measurement\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "906341ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Il numero migliore di feature è: 5\n",
      "Il MAE con il numero di feature ottimale è: 332.4652202022095\n"
     ]
    }
   ],
   "source": [
    "# Traina il modello sulle feature selezionate\n",
    "model.fit(data[selected_features], data[\"pv_measurement\"])\n",
    "# Calcola il MAE con le feature selezionate\n",
    "y_pred = model.predict(data[selected_features])\n",
    "mae = mean_absolute_error(data[\"pv_measurement\"], y_pred)\n",
    "print(\"Il numero migliore di feature è:\", n_features)\n",
    "print(\"Il MAE con il numero di feature ottimale è:\", mae)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c14cbb3e",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "AdaBoostRegressor.__init__() got an unexpected keyword argument 'verbose'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 28\u001b[0m\n\u001b[0;32m     26\u001b[0m X_test_pca \u001b[38;5;241m=\u001b[39m pca\u001b[38;5;241m.\u001b[39mtransform(X_test)[:, :n_components]\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Train the XGBoost model\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m model \u001b[38;5;241m=\u001b[39m AdaBoostRegressor(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparam)\n\u001b[0;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39mfit(X_train_pca, y_train)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Make predictions on the test data\u001b[39;00m\n",
      "\u001b[1;31mTypeError\u001b[0m: AdaBoostRegressor.__init__() got an unexpected keyword argument 'verbose'"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "data = df_normalized\n",
    "# Esegui una PCA\n",
    "pca = PCA()\n",
    "pca.fit(data.drop(columns  = 'pv_measurement'))\n",
    "\n",
    "# Salva le componenti principali\n",
    "components = pca.components_\n",
    "param = {'verbose' : -1}\n",
    "\n",
    "# Calcola l'errore di previsione per ogni numero di componenti\n",
    "maelist = []\n",
    "for n_components in range(1, len(components) + 1):\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        train_data = data.iloc[train_index]\n",
    "        test_data = data.iloc[test_index]\n",
    "\n",
    "        # Extract target variable for training and testing data\n",
    "        y_train = train_data['pv_measurement']\n",
    "        y_test = test_data['pv_measurement']\n",
    "\n",
    "        # Extract features for training and testing data\n",
    "        X_train = train_data.drop(columns = 'pv_measurement')\n",
    "        X_test = test_data.drop(columns = 'pv_measurement')\n",
    "        X_train_pca = pca.transform(X_train)[:, :n_components]\n",
    "        X_test_pca = pca.transform(X_test)[:, :n_components]\n",
    "        # Train the XGBoost model\n",
    "        model = AdaBoostRegressor(**param)\n",
    "        model.fit(X_train_pca, y_train)\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test_pca)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        print(\"Mean Absolute Error:\", mae)\n",
    "    maelist.append(mae)\n",
    "\n",
    "# Trova il numero di componenti con il minimo errore\n",
    "min_error_index = np.argmin(maelist)\n",
    "n_components = min_error_index + 1\n",
    "\n",
    "print(\"Il numero migliore di componenti è:\", n_components)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e336764",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_categorical(\"n_estimators\", [50, 100, 200])\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 0.1, 1.0)\n",
    "    max_depth = trial.suggest_int(\"max_depth\", 1, 10)\n",
    "    model = AdaBoostRegressor(**param)\n",
    "    maelist = []\n",
    "    for train_index, test_index in tscv.split(data):\n",
    "        train_data = data.iloc[train_index]\n",
    "        test_data = data.iloc[test_index]\n",
    "\n",
    "        # Extract target variable for training and testing data\n",
    "        y_train = train_data['pv_measurement']\n",
    "        y_test = test_data['pv_measurement']\n",
    "\n",
    "        # Extract features for training and testing data\n",
    "        X_train = train_data.drop(columns = 'pv_measurement')\n",
    "        X_test = test_data.drop(columns = 'pv_measurement')\n",
    "        \n",
    "        # Train the XGBoost model\n",
    "        model.fit(X_train, y_train,eval_set=[(X_test,y_test)])\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        # Evaluate the model using Mean Absolute Error (MAE)\n",
    "        mae = mean_absolute_error(y_test, y_pred)\n",
    "        print(\"Mean Absolute Error:\", mae)\n",
    "        maelist.append(mae)\n",
    "    # Return MAE\n",
    "    mean_mae = np.mean(maelist)\n",
    "\n",
    "    return mean_mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17b7fd2-ba56-44d6-a799-b477b9d5ad22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from warnings import simplefilter\n",
    "simplefilter(\"ignore\", category=RuntimeWarning)\n",
    "study = optuna.create_study(direction='minimize')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81030038-4079-4a9d-8219-5c9be4b988f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "study.optimize(objective, n_trials=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b87db151-dec5-4b3f-9604-ac46ec2297f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "\n",
    "print(\"  Value: {}\".format(trial.value))\n",
    "print(trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e39e62c4-d842-4e6e-a67f-da452a79e678",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'n_estimators': 648, 'reg_alpha': 0.18734665099633893, 'reg_lambda': 0.15271069876903318, 'colsample_bytree': 0.5, 'subsample': 0.8, 'learning_rate': 0.011131612016333637, 'max_depth': 27, 'num_leaves': 177, 'min_child_samples': 122, 'min_data_per_groups': 75}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a5d7bb0-91cb-4cc5-862d-025e403cf6c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A = AdaBoostRegressor(**param)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cb0791-4848-49f6-bbc3-03518bc4f94d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = df.drop(columns = 'pv_measurement')\n",
    "y_train = df['pv_measurement']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "871b3461-0ce0-4353-bf3f-207d6ed0c79f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_A.fit(X_train,y_train)\n",
    "df_test_A = df_test_A\n",
    "y_pred_A = model_A.predict(df_test_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e6ab7b3-fdcb-492b-bac4-890a12480f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(len(y_pred_A)), y_pred_A, label='Predizione', color='red', linestyle='-')\n",
    "\n",
    "# Aggiungi una legenda\n",
    "plt.legend()\n",
    "\n",
    "# Aggiungi etichette agli assi\n",
    "plt.ylabel('Valori y')\n",
    "\n",
    "# Titolo del grafico\n",
    "plt.title('Grafico di Predizione')\n",
    "\n",
    "# Mostra il grafico\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006f3c40-6b7b-41a6-bf5d-decb0321db8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({'Prediction':y_pred_A})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c340aac0-1709-4090-a725-e58f968cff11",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.05\n",
    "df['Prediction'] = df['Prediction'].apply(lambda x: 0 if x < threshold else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33dac465-12c8-4234-9328-0639f338f50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('A1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ebad8e5-6ecb-4225-a64b-637db86272cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468cd57d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m112",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m112"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
