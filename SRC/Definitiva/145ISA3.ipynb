{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "from catboost import CatBoostRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from pycaret.regression import *\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "\n",
    "pd.set_option('display.max_rows', 200)\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD TIME FEATURES\n",
    "def add_time_features(df, time_column, mode = 'lgbm'):\n",
    "    '''\n",
    "        This function will add some time feature based on the param 'time_columns'\n",
    "        \n",
    "        Params:\n",
    "            df-> Dataframe with the column contained in 'time_column'\n",
    "            time_column -> the column that is a datetime object\n",
    "        \n",
    "        Returns:\n",
    "            A dataframe with time features\n",
    "    '''\n",
    "    \n",
    "    df[time_column] = pd.to_datetime(df[time_column])  # Make sure the time column is in datetime format\n",
    "    if mode == 'lgbm':\n",
    "        df['hour'] = df[time_column].dt.hour\n",
    "        df['day_of_week'] = df[time_column].dt.dayofweek\n",
    "        df['month'] = df[time_column].dt.month\n",
    "        df['day_of_year'] = df[time_column].dt.dayofyear\n",
    "        df['week_of_year'] = df[time_column].dt.isocalendar().week\n",
    "        df['year'] = df[time_column].dt.year\n",
    "    elif mode == 'cat_boost':\n",
    "        df['day_of_week'] = df[time_column].dt.dayofweek\n",
    "        df['sin_hour'] = np.sin(2*np.pi * df[time_column].dt.hour/23.)\n",
    "        df['sin_month'] = np.sin(2*np.pi * df[time_column].dt.month/12.)\n",
    "        df['cos_hour'] = np.cos(2*np.pi * df[time_column].dt.hour/23.)\n",
    "        df['cos_month'] = np.cos(2*np.pi * df[time_column].dt.month/12.)\n",
    "    elif mode == 'cat':\n",
    "        df['sin_hour'] = np.sin(2*np.pi * df[time_column].dt.hour/23.)\n",
    "        df['sin_month'] = np.sin(2*np.pi * df[time_column].dt.month/12.)   \n",
    "    \n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_datetime(df,column):\n",
    "    '''\n",
    "        Make the column in datetime format\n",
    "    '''\n",
    "    return pd.to_datetime(df[column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resampling(df,column):\n",
    "    '''\n",
    "        Resample df to 1 hour using mean() as aggregator and drop rows where all columns are NaN\n",
    "        \n",
    "        Params :\n",
    "            df -> the dataframe to be resampled\n",
    "            column -> the time column\n",
    "    '''\n",
    "    return df.set_index(keys = column).resample('1H').mean().dropna(how='all').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_df(df,columnlist):\n",
    "    return df.drop(columns = columnlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_data_calc(df):\n",
    "    '''\n",
    "    This function create a dataframe with 'date_forecast' as index and the column 'date_calc' resampled by '1H'.\n",
    "    If there's no data in a specific bin, the resulting value for that bin would be NaN (not a number).\n",
    "    Params:\n",
    "        df -> dataframe with 'date_forecast' and 'date_calc' columns.\n",
    "            'date_calc' is expected to contain data that the user wants to resample or analyze.\n",
    "    Returns:\n",
    "        A dataframe with 'date_calc' resampled.\n",
    "    '''\n",
    "    return df.set_index('date_forecast')['date_calc'].resample('1H').first().to_frame()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_estimated_feature(df):\n",
    "    '''\n",
    "        This function will create some time feature and estimated information. It's need to let the model understand is\n",
    "        estimated value.\n",
    "        Params:\n",
    "            df -> It MUST be an estimated dataframe, that contains 'data_forecast' as datetime type\n",
    "        Returns:\n",
    "            A dataframe with 'time_dummy', 'time_delta' and 'is_estimated'     \n",
    "    '''\n",
    "    df['time_delta'] = (df['date_calc'] - df['date_forecast']).dt.total_seconds() / 3600\n",
    "    df['is_estimated'] = 1\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stationarity(df):\n",
    "    '''\n",
    "    Removes constant stretches of data within a DataFrame where the 'pv_measurement' column does not change.    \n",
    "    The function identifies blocks of data where the 'pv_measurement' stays constant for more than two consecutive\n",
    "    points and removes these blocks to address data stationarity.\n",
    "\n",
    "    params:\n",
    "        df -> DataFrame\n",
    "              A pandas DataFrame with a 'pv_measurement' column which contains the data from which to remove stationarity.\n",
    "        \n",
    "    return:\n",
    "        The DataFrame with constant stretches of data removed from the 'pv_measurement' column.\n",
    "    '''\n",
    "    \n",
    "    #Calculate the difference, this need for check the constant\n",
    "    df['diff'] = df['pv_measurement'].diff().fillna(0)\n",
    "\n",
    "    # Create an indicator for constant stretches\n",
    "    df['constant'] = (df['diff'] == 0).astype(int)\n",
    "\n",
    "    # Use the indicator to mark stretches. The diff() function here identifies change-points.\n",
    "    df['block'] = (df['constant'].diff() != 0).astype(int).cumsum()\n",
    "\n",
    "    # Get the size of each constant block\n",
    "    block_sizes = df.groupby('block')['constant'].sum()\n",
    "\n",
    "    # Identify blocks that are constant for more than N consecutive time points (in this case 2)\n",
    "    constant_blocks = block_sizes[block_sizes > 2].index\n",
    "    \n",
    "    # Remove the constant\n",
    "    filtered_df = df[~df['block'].isin(constant_blocks)]\n",
    "        \n",
    "    return filtered_df.drop(columns=['diff', 'constant', 'block'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(targets, observed, estimated, test, mode: str = 'lgbm'):\n",
    "    '''\n",
    "        This function makes all the preprocessing needed for the correct run of the model, it will perform:\n",
    "            - Resampling\n",
    "            - Filtering\n",
    "            - Imputation\n",
    "            - Outliers removal\n",
    "            - Categorical Encoding\n",
    "        \n",
    "        Params:\n",
    "            targets -> dataframe of the target parquet\n",
    "            observed -> dataframe of observed train data\n",
    "            estimated -> dataframe of estimated train data\n",
    "            test -> dataframe of test data\n",
    "        Returns:\n",
    "            train_data -> dataframe of all data ready to train\n",
    "            test_data -> dataframe of all data ready to test\n",
    "            is_day -> dataframe of is_day categorical feature for post processing\n",
    "    \n",
    "    '''    \n",
    "    targets['time'] = to_datetime(targets,'time')\n",
    "    estimated['date_forecast'] = to_datetime(estimated,'date_forecast')\n",
    "    observed['date_forecast'] = to_datetime(observed,'date_forecast')\n",
    "    test['date_forecast'] = to_datetime(test,'date_forecast')\n",
    "\n",
    "    observed_resampled = resampling(observed,'date_forecast')\n",
    "    estimated_resampled = resampling(estimated,'date_forecast')\n",
    "    test_resampled = resampling(test,'date_forecast')\n",
    "    \n",
    "    date_calc_resampled_observed = extract_data_calc(estimated)\n",
    "    date_calc_resampled_test = extract_data_calc(test)\n",
    "    \n",
    "    estimated_resampled = estimated_resampled.merge(date_calc_resampled_observed, left_on='date_forecast', right_index=True)\n",
    "    test_resampled = test_resampled.merge(date_calc_resampled_test, left_on='date_forecast', right_index=True)\n",
    "    \n",
    "    is_day = test_resampled[['date_forecast', 'is_day:idx']]   \n",
    "    test_resampled = filter_df(test_resampled,['is_day:idx', 'snow_density:kgm3','elevation:m'])\n",
    "    observed_resampled = filter_df(observed_resampled,['is_day:idx', 'snow_density:kgm3','elevation:m']) \n",
    "    estimated_resampled = filter_df(estimated_resampled,[ 'is_day:idx', 'snow_density:kgm3','elevation:m'])\n",
    "    \n",
    "    #This MUST be zero because is not estimated.\n",
    "    observed_resampled['is_estimated'] = 0\n",
    "    observed_resampled['time_delta'] = 0\n",
    "    \n",
    "    estimated_resampled = is_estimated_feature(estimated_resampled)\n",
    "    test_resampled = is_estimated_feature(test_resampled)\n",
    "    \n",
    "    X = pd.concat([observed_resampled,estimated_resampled],axis = 0)\n",
    "    train_data = pd.merge(targets, X, how='inner', left_on='time', right_on='date_forecast')\n",
    "    if mode == 'lgbm':\n",
    "        train_data = add_time_features(train_data, 'time')\n",
    "        test_data = add_time_features(test_resampled, 'date_forecast')\n",
    "    elif mode == 'cat':\n",
    "        train_data = add_time_features(train_data, 'time', mode = 'cat')\n",
    "        test_data = add_time_features(test_resampled, 'date_forecast', mode = 'cat')\n",
    "        train_data = train_data[train_data['date_forecast'].dt.month.isin([4,5,6,7,8])]\n",
    "        test_data = test_data[test_data['date_forecast'].dt.month.isin([4,5,6,7,8])]\n",
    "    elif mode == 'cat_boost':\n",
    "        train_data = add_time_features(train_data, 'time', mode = 'cat_boost')\n",
    "        test_data = add_time_features(test_resampled, 'date_forecast', mode = 'cat_boost')\n",
    "\n",
    "    \n",
    "    train_data = delete_stationarity(train_data)\n",
    "    \n",
    "    train_data = filter_df(train_data, ['time','date_calc'])\n",
    "    test_data = filter_df(test_resampled, ['date_calc'])\n",
    "\n",
    "    return train_data, test_data, is_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LightGBM with some extra features\n",
    "def process_location(X, y, location_name,seeds):\n",
    "    # Combine feature data and target into a single DataFrame\n",
    "    data = X.copy()\n",
    "    data['target'] = y['pv_measurement']\n",
    "    \n",
    "    # Setup the environment in PyCaret\n",
    "    exp_reg = setup(data=data, target='target', session_id=seeds,\n",
    "                    categorical_features=['dew_or_rime:idx', 'is_in_shadow:idx','is_estimated'],\n",
    "                    imputation_type=\"iterative\", categorical_iterative_imputer=\"lightgbm\", numeric_iterative_imputer=\"lightgbm\", iterative_imputation_iters = 5,\n",
    "                    html=False, \n",
    "                    experiment_name=f'exp_{location_name}')\n",
    "\n",
    "    # Create a LightGBM model\n",
    "    lightgbm = create_model('lightgbm')\n",
    "    \n",
    "    # Tune the model\n",
    "    tuned_lightgbm = tune_model(lightgbm, optimize='MAE')\n",
    "\n",
    "    # Create a bagged version of the tuned model\n",
    "    bagged_lightgbm = ensemble_model(tuned_lightgbm, method='Bagging')\n",
    "\n",
    "    # Finalize the model by training on whole dataset\n",
    "    final_model = finalize_model(bagged_lightgbm)\n",
    "\n",
    "    # Save the model for future use\n",
    "    save_model(final_model, f'final_model_for_location_{location_name}')\n",
    "        \n",
    "    return final_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def feature_engineering(data):\n",
    "    # Added some extra features to this one model, did it here so we could reuse the same preprocesssing function on diffrent models\n",
    "    # Feature Combination 1: Solar Radiation and Cloud Cover Combination\n",
    "    data['weighted_rad'] = ((data['direct_rad:W'] * (1 - data['total_cloud_cover:p']/100)) +\n",
    "                        (data['diffuse_rad:W'] * (data['total_cloud_cover:p']/100)))\n",
    "\n",
    "    # Feature Combination 2: Atmospheric Conditions Combination\n",
    "    data['adjusted_clear_sky_rad'] = (data['clear_sky_rad:W'] *\n",
    "                                  np.exp(-0.0001 * data['absolute_humidity_2m:gm3']) *\n",
    "                                  (1 - 0.1 * (data['air_density_2m:kgm3'] - 1.225)))  # Adjusted based on humidity and air density\n",
    "    data['solar_incidence_factor'] = np.cos(np.radians(90 - data['sun_elevation:d'])) * np.cos(np.radians(data['sun_azimuth:d']))\n",
    "    data['seasonal_conversion_efficiency'] = data['weighted_rad'] * (1 - data['relative_humidity_1000hPa:p']/100) * (data['msl_pressure:hPa'] / 1013.25)\n",
    "    \n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some global lists to save predictions in\n",
    "locations = ['A', 'B', 'C']\n",
    "all_predictions_lGBM = []\n",
    "all_predictions_lGBM_e = []\n",
    "all_predictions_rf = []\n",
    "all_predictions_lasso = []\n",
    "all_predictions_cat = []\n",
    "all_predictions_cat_2 = []\n",
    "final_df_list = [] \n",
    "all_pred_stacked =[]\n",
    "all_predictions_cat_3=[]\n",
    "\n",
    "all_X_train_cat = pd.DataFrame()\n",
    "all_X_test_cat = pd.DataFrame()\n",
    "all_is_day_feature1 = pd.Series(dtype='float64')\n",
    "all_targets_cat = pd.DataFrame()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        Description        Value\n",
      "0                        Session id           42\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (19622, 55)\n",
      "4            Transformed data shape  (19622, 67)\n",
      "5       Transformed train set shape  (13735, 67)\n",
      "6        Transformed test set shape   (5887, 67)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        20.2%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_A\n",
      "24                              USI         4e63\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     310.2230  273202.6471  522.6879  0.8613  1.0853  1.9864\n",
      "1     299.0549  254415.8433  504.3965  0.8585  1.1656  2.4947\n",
      "2     307.1856  275831.0135  525.1962  0.8553  1.0775  2.4394\n",
      "3     322.0855  293524.1154  541.7787  0.8505  1.0877  1.7441\n",
      "4     306.2584  245169.7561  495.1462  0.8701  1.0745  2.7818\n",
      "5     304.6759  276448.5465  525.7837  0.8538  1.1579  2.4854\n",
      "6     308.0701  269758.9885  519.3833  0.8391  1.1275  3.3045\n",
      "7     306.5295  265946.7614  515.7003  0.8601  1.0957  3.4485\n",
      "8     315.4189  274251.8715  523.6906  0.8525  1.0566  1.9057\n",
      "9     311.2788  286220.6045  534.9959  0.8430  1.1044  2.1519\n",
      "Mean  309.0780  271477.0148  520.8759  0.8544  1.1033  2.4742\n",
      "Std     5.9535   13320.9981   12.8564  0.0085  0.0343  0.5416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     313.2298  278308.8581  527.5499  0.8587  1.1585  1.9501\n",
      "1     309.3468  269268.1434  518.9105  0.8502  1.2519  3.0296\n",
      "2     307.9427  280229.4251  529.3670  0.8530  1.1749  3.2426\n",
      "3     326.1188  297647.8075  545.5711  0.8484  1.1125  1.9030\n",
      "4     307.4927  253172.8048  503.1628  0.8658  1.1996  3.1029\n",
      "5     303.1808  272931.2645  522.4282  0.8557  1.2111  2.6367\n",
      "6     312.5930  281852.1829  530.8975  0.8319  1.1967  3.6350\n",
      "7     302.0644  257202.1888  507.1511  0.8647  1.2025  3.4493\n",
      "8     316.6752  277554.1709  526.8341  0.8507  1.1982  2.7345\n",
      "9     314.7728  294089.0496  542.2998  0.8387  1.1413  2.9538\n",
      "Mean  311.3417  276225.5895  525.4172  0.8518  1.1847  2.8638\n",
      "Std     6.6838   13358.0998   12.7419  0.0101  0.0374  0.5477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     314.6244  280969.4244  530.0655  0.8573  1.0286  1.5416\n",
      "1     302.0399  260054.6417  509.9555  0.8554  1.0883  2.2941\n",
      "2     311.4288  280928.3584  530.0268  0.8526  1.0985  2.8713\n",
      "3     326.9863  304725.6033  552.0196  0.8448  1.0166  1.6375\n",
      "4     305.1731  244459.7811  494.4287  0.8705  1.0451  2.6943\n",
      "5     302.6081  275160.5440  524.5575  0.8545  1.0947  2.3392\n",
      "6     310.1370  270238.0240  519.8442  0.8389  1.0763  3.1113\n",
      "7     304.1020  265488.3864  515.2557  0.8604  1.0723  2.9576\n",
      "8     312.4422  274824.6165  524.2372  0.8522  1.0176  1.9147\n",
      "9     308.2166  286711.1876  535.4542  0.8427  1.0364  1.9941\n",
      "Mean  309.7759  274356.0568  523.5845  0.8529  1.0574  2.3356\n",
      "Std     7.0478   15351.4452   14.6748  0.0087  0.0305  0.5308\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "                        Description        Value\n",
      "0                        Session id          123\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (19622, 55)\n",
      "4            Transformed data shape  (19622, 67)\n",
      "5       Transformed train set shape  (13735, 67)\n",
      "6        Transformed test set shape   (5887, 67)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        20.2%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_A\n",
      "24                              USI         4596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     299.9363  261785.1309  511.6494  0.8544  1.0844  2.4444\n",
      "1     321.8247  292466.3033  540.8015  0.8421  1.1234  1.8595\n",
      "2     307.5598  267317.6653  517.0277  0.8484  1.0888  3.1074\n",
      "3     295.2908  239820.2811  489.7145  0.8685  1.0341  1.9681\n",
      "4     322.5253  290795.2864  539.2544  0.8426  1.0496  2.4292\n",
      "5     334.5336  311891.9066  558.4728  0.8269  1.0622  2.0647\n",
      "6     312.5375  270096.0050  519.7076  0.8560  1.1231  2.2184\n",
      "7     315.6672  280945.0016  530.0425  0.8578  1.0690  2.5388\n",
      "8     297.5678  267930.6848  517.6202  0.8535  1.0539  2.8401\n",
      "9     288.5257  243804.5021  493.7656  0.8717  1.1364  2.4439\n",
      "Mean  309.5969  272685.2767  521.8056  0.8522  1.0825  2.3914\n",
      "Std    13.6925   21013.7725   20.1038  0.0124  0.0333  0.3662\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     302.1471  267787.1762  517.4816  0.8510  1.1280  2.7228\n",
      "1     315.5948  289681.7695  538.2209  0.8436  1.1403  1.9823\n",
      "2     306.0767  261043.1810  510.9239  0.8520  1.1544  3.4059\n",
      "3     293.9771  237044.6747  486.8723  0.8701  1.1234  2.0639\n",
      "4     324.0204  294660.5859  542.8265  0.8405  1.1584  2.9377\n",
      "5     336.6670  317151.5209  563.1621  0.8240  1.1248  2.2087\n",
      "6     317.7921  286581.0082  535.3326  0.8472  1.1736  2.1218\n",
      "7     311.9533  281629.1095  530.6874  0.8575  1.1215  2.4755\n",
      "8     293.9081  259405.2836  509.3185  0.8582  1.1972  2.7669\n",
      "9     280.7995  234733.3418  484.4929  0.8765  1.1604  2.5495\n",
      "Mean  308.2936  272971.7651  521.9319  0.8520  1.1482  2.5235\n",
      "Std    15.5558   24632.8936   23.6411  0.0142  0.0238  0.4262\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           MAE          MSE      RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                         \n",
      "0     298.0121  259377.5615  509.2912  0.8557  1.0268  2.2656\n",
      "1     315.6434  287461.7531  536.1546  0.8448  1.0431  1.7083\n",
      "2     299.1230  256437.2997  506.3964  0.8546  1.0376  2.6144\n",
      "3     285.0867  227737.6085  477.2186  0.8752  1.0358  1.9707\n",
      "4     314.8975  284693.1218  533.5664  0.8459  1.0353  2.1832\n",
      "5     326.5729  300890.6659  548.5350  0.8331  1.0183  1.8943\n",
      "6     309.4515  271803.2660  521.3475  0.8551  1.0420  1.7914\n",
      "7     311.1823  281940.3131  530.9805  0.8573  0.9962  2.0429\n",
      "8     291.4587  259145.0570  509.0629  0.8583  1.0324  1.8348\n",
      "9     280.7790  232887.9170  482.5846  0.8774  1.0781  2.1695\n",
      "Mean  303.2207  266237.4564  515.5138  0.8557  1.0346  2.0475\n",
      "Std    13.9748   22488.4830   21.9770  0.0126  0.0196  0.2564\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "[LightGBM] [Warning] feature_fraction is set=0.4, colsample_bytree=1.0 will be ignored. Current value: feature_fraction=0.4\n",
      "[LightGBM] [Warning] bagging_fraction is set=0.6, subsample=1.0 will be ignored. Current value: bagging_fraction=0.6\n",
      "[LightGBM] [Warning] bagging_freq is set=2, subsample_freq=0 will be ignored. Current value: bagging_freq=2\n",
      "                        Description        Value\n",
      "0                        Session id           42\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (13473, 55)\n",
      "4            Transformed data shape  (13473, 67)\n",
      "5       Transformed train set shape   (9431, 67)\n",
      "6        Transformed test set shape   (4042, 67)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        17.3%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_B\n",
      "24                              USI         b36e\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     48.9960  7070.7580  84.0878  0.8969  0.8381  1.5630\n",
      "1     47.0249  6755.6431  82.1927  0.8991  0.8417  1.5689\n",
      "2     53.6609  9792.4154  98.9566  0.8503  0.8095  1.3646\n",
      "3     48.8259  7354.8449  85.7604  0.8858  0.8278  2.0641\n",
      "4     48.3632  7236.0509  85.0650  0.8868  0.8556  1.1172\n",
      "5     47.9635  6543.8838  80.8943  0.8961  0.8734  1.5897\n",
      "6     55.0159  8212.8208  90.6246  0.8792  0.8978  1.6338\n",
      "7     51.3328  7319.8684  85.5562  0.8923  0.7836  1.0596\n",
      "8     48.5277  6821.5999  82.5930  0.8959  0.8569  1.6791\n",
      "9     47.1046  6148.0507  78.4095  0.9072  0.8095  1.1904\n",
      "Mean  49.6815  7325.5936  85.4140  0.8890  0.8394  1.4830\n",
      "Std    2.6065   975.8463   5.4809  0.0149  0.0319  0.2893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     48.9512  7026.3158  83.8231  0.8976  0.8860  2.0005\n",
      "1     47.5178  6973.7975  83.5093  0.8959  0.8577  1.5936\n",
      "2     54.4331  9780.7643  98.8977  0.8505  0.8287  1.3616\n",
      "3     49.9346  8042.2220  89.6784  0.8751  0.8384  2.2953\n",
      "4     49.7536  7895.4536  88.8564  0.8765  0.8727  1.1204\n",
      "5     46.9338  6259.3467  79.1160  0.9006  0.9367  1.4997\n",
      "6     55.0627  8157.4278  90.3185  0.8800  0.9136  1.6371\n",
      "7     50.5617  7229.4396  85.0261  0.8936  0.7575  1.0403\n",
      "8     50.3756  7097.1206  84.2444  0.8917  0.9075  1.8890\n",
      "9     47.4060  6196.0557  78.7150  0.9064  0.8393  1.3855\n",
      "Mean  50.0930  7465.7944  86.2185  0.8868  0.8638  1.5823\n",
      "Std    2.6289  1002.4499   5.6714  0.0157  0.0491  0.3717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     50.1183  7447.5901  86.2994  0.8914  0.8232  1.5792\n",
      "1     47.4349  7112.7802  84.3373  0.8938  0.8155  1.5315\n",
      "2     53.0926  9375.0240  96.8247  0.8567  0.7911  1.4493\n",
      "3     48.9194  7541.6300  86.8426  0.8829  0.8094  2.2005\n",
      "4     49.0471  7486.8330  86.5265  0.8829  0.8382  1.1288\n",
      "5     47.7065  6474.0982  80.4618  0.8972  0.8623  1.5331\n",
      "6     54.0398  8030.6692  89.6140  0.8819  0.8662  1.6009\n",
      "7     51.1579  7233.6385  85.0508  0.8935  0.7579  1.0350\n",
      "8     48.0263  6722.5813  81.9913  0.8974  0.8189  1.6310\n",
      "9     46.6042  6020.1941  77.5899  0.9091  0.7733  1.1954\n",
      "Mean  49.6147  7344.5039  85.5538  0.8887  0.8156  1.4885\n",
      "Std    2.3473   873.3702   5.0046  0.0133  0.0333  0.3122\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "                        Description        Value\n",
      "0                        Session id          123\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (13473, 55)\n",
      "4            Transformed data shape  (13473, 66)\n",
      "5       Transformed train set shape   (9431, 66)\n",
      "6        Transformed test set shape   (4042, 66)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        17.3%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_B\n",
      "24                              USI         0677\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     46.9314  6414.0499  80.0878  0.9030  0.7991  1.2843\n",
      "1     55.1828  8485.5039  92.1168  0.8757  0.7952  1.2794\n",
      "2     52.6451  7852.1197  88.6122  0.8758  0.8268  1.4871\n",
      "3     48.8623  7536.6173  86.8137  0.8880  0.7819  1.2645\n",
      "4     47.1979  6771.7838  82.2908  0.8943  0.8479  7.7770\n",
      "5     48.6593  7308.8530  85.4918  0.8917  0.8886  2.0210\n",
      "6     47.8624  6778.0835  82.3291  0.8977  0.9132  2.1079\n",
      "7     49.2003  8003.4263  89.4619  0.8820  0.8052  1.1821\n",
      "8     49.4943  7157.1215  84.5998  0.8852  0.8667  1.7908\n",
      "9     54.0456  9027.5123  95.0132  0.8628  0.8112  1.9480\n",
      "Mean  50.0081  7533.5071  86.6817  0.8856  0.8336  2.2142\n",
      "Std    2.7577   778.2612   4.4484  0.0114  0.0417  1.8836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "          MAE        MSE     RMSE      R2   RMSLE     MAPE\n",
      "Fold                                                      \n",
      "0     48.3161  6805.0940  82.4930  0.8971  0.8099   1.1715\n",
      "1     56.8564  9181.8562  95.8220  0.8655  0.7734   1.0873\n",
      "2     55.3279  8698.6879  93.2668  0.8624  0.8094   1.3494\n",
      "3     51.8586  8330.7958  91.2732  0.8761  0.8006   1.2597\n",
      "4     46.6508  6845.9487  82.7402  0.8932  0.8351  39.7010\n",
      "5     48.1757  7341.4332  85.6822  0.8912  0.8551   1.4381\n",
      "6     48.4873  6742.2308  82.1111  0.8982  0.8669   1.8017\n",
      "7     50.2644  8260.5900  90.8878  0.8782  0.8293   1.2037\n",
      "8     50.9860  7725.9745  87.8975  0.8760  0.8307   2.1490\n",
      "9     53.5530  8655.0903  93.0327  0.8684  0.7997   1.7794\n",
      "Mean  51.0476  7858.7702  88.5206  0.8806  0.8210   5.2941\n",
      "Std    3.1814   845.1263   4.7817  0.0127  0.0265  11.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE     MAPE\n",
      "Fold                                                      \n",
      "0     46.3860  6216.0817  78.8421  0.9060  0.7694   1.3339\n",
      "1     55.8818  8511.9863  92.2604  0.8753  0.7812   1.3415\n",
      "2     52.4151  7840.7186  88.5478  0.8759  0.8001   1.4268\n",
      "3     48.9449  7389.9997  85.9651  0.8901  0.7816   1.2914\n",
      "4     46.8720  6752.9755  82.1765  0.8946  0.8308  52.4978\n",
      "5     48.3957  7219.8472  84.9697  0.8930  0.8516   1.9202\n",
      "6     47.1982  6405.1377  80.0321  0.9033  0.8843   2.0416\n",
      "7     49.4075  7856.1398  88.6349  0.8842  0.7976   1.2346\n",
      "8     49.5065  6978.5519  83.5377  0.8880  0.8149   1.7863\n",
      "9     53.0825  8611.1941  92.7965  0.8691  0.7949   1.4540\n",
      "Mean  49.8090  7378.2633  85.7763  0.8880  0.8107   6.6328\n",
      "Std    2.9076   782.3876   4.5488  0.0115  0.0339  15.2907\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "                        Description        Value\n",
      "0                        Session id           42\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (11023, 55)\n",
      "4            Transformed data shape  (11023, 67)\n",
      "5       Transformed train set shape   (7716, 67)\n",
      "6        Transformed test set shape   (3307, 67)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        23.0%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_C\n",
      "24                              USI         fb8c\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     43.0832  5233.8293  72.3452  0.8957  0.7793  0.6213\n",
      "1     45.5000  6163.6976  78.5092  0.8735  0.7160  0.5981\n",
      "2     44.4576  5531.9945  74.3774  0.8768  0.7529  0.5200\n",
      "3     38.9623  4000.1756  63.2469  0.9159  0.7456  0.5119\n",
      "4     43.6505  5312.5825  72.8875  0.8885  0.7125  0.5440\n",
      "5     42.9988  5229.9332  72.3183  0.8955  0.7085  0.5643\n",
      "6     42.6852  5006.0038  70.7531  0.8932  0.8047  0.5967\n",
      "7     46.4997  6207.9372  78.7905  0.8588  0.8251  0.8038\n",
      "8     44.9686  5807.2804  76.2055  0.8775  0.7788  0.6274\n",
      "9     42.9722  5763.0818  75.9150  0.8614  0.7524  0.6118\n",
      "Mean  43.5778  5425.6516  73.5349  0.8837  0.7576  0.5999\n",
      "Std    1.9492   610.2019   4.2751  0.0166  0.0375  0.0784\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     42.8463  5382.9565  73.3686  0.8928  0.7779  0.5963\n",
      "1     45.7138  6069.1475  77.9047  0.8754  0.7291  0.6246\n",
      "2     45.3100  5505.8173  74.2012  0.8774  0.7892  0.6147\n",
      "3     39.3652  4016.8643  63.3787  0.9155  0.7730  0.5440\n",
      "4     44.8579  5711.1229  75.5720  0.8801  0.7317  0.5816\n",
      "5     43.1582  5125.5638  71.5930  0.8976  0.7124  0.5426\n",
      "6     43.7395  5264.2547  72.5552  0.8876  0.8456  0.5852\n",
      "7     45.2053  6074.2170  77.9373  0.8618  0.8409  0.7463\n",
      "8     44.6330  5503.4901  74.1855  0.8839  0.8042  0.6420\n",
      "9     43.0042  5554.3783  74.5277  0.8664  0.7415  0.6422\n",
      "Mean  43.7834  5420.7812  73.5224  0.8839  0.7746  0.6119\n",
      "Std    1.7707   552.0546   3.9036  0.0148  0.0440  0.0560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     42.2376  5131.9256  71.6375  0.8978  0.7675  0.6185\n",
      "1     44.8651  5916.5076  76.9188  0.8786  0.7108  0.6254\n",
      "2     44.7663  5459.3031  73.8871  0.8784  0.7372  0.5227\n",
      "3     37.8876  3907.1564  62.5073  0.9178  0.7444  0.5498\n",
      "4     43.9335  5472.6896  73.9776  0.8851  0.7094  0.5852\n",
      "5     42.5302  4995.8445  70.6813  0.9002  0.6896  0.5543\n",
      "6     43.9774  5374.6465  73.3120  0.8853  0.8220  0.6810\n",
      "7     45.7340  6127.3515  78.2774  0.8606  0.8328  0.8719\n",
      "8     45.3512  5838.9803  76.4132  0.8769  0.7628  0.6784\n",
      "9     43.0194  5647.0810  75.1471  0.8642  0.7308  0.6394\n",
      "Mean  43.4302  5387.1486  73.2759  0.8845  0.7507  0.6327\n",
      "Std    2.1567   593.3930   4.2176  0.0163  0.0446  0.0945\n",
      "Transformation Pipeline and Model Successfully Saved\n",
      "                        Description        Value\n",
      "0                        Session id          123\n",
      "1                            Target       target\n",
      "2                       Target type   Regression\n",
      "3               Original data shape  (11023, 55)\n",
      "4            Transformed data shape  (11023, 67)\n",
      "5       Transformed train set shape   (7716, 67)\n",
      "6        Transformed test set shape   (3307, 67)\n",
      "7                  Ordinal features            1\n",
      "8                  Numeric features           51\n",
      "9              Categorical features            3\n",
      "10         Rows with missing values        23.0%\n",
      "11                       Preprocess         True\n",
      "12                  Imputation type    iterative\n",
      "13  Iterative imputation iterations            5\n",
      "14        Numeric iterative imputer     lightgbm\n",
      "15    Categorical iterative imputer     lightgbm\n",
      "16         Maximum one-hot encoding           25\n",
      "17                  Encoding method         None\n",
      "18                   Fold Generator        KFold\n",
      "19                      Fold Number           10\n",
      "20                         CPU Jobs           -1\n",
      "21                          Use GPU        False\n",
      "22                   Log Experiment        False\n",
      "23                  Experiment Name        exp_C\n",
      "24                              USI         efac\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     45.3362  5389.0193  73.4099  0.8922  0.7562  0.5600\n",
      "1     40.7585  4525.8876  67.2747  0.9030  0.7286  0.6090\n",
      "2     43.1949  5570.3385  74.6347  0.8660  0.7373  0.5792\n",
      "3     41.2055  4921.5067  70.1535  0.8920  0.7672  0.7804\n",
      "4     45.6015  5997.1158  77.4410  0.8683  0.7089  0.5424\n",
      "5     44.0639  5596.5630  74.8102  0.8845  0.7216  0.5879\n",
      "6     43.2800  5130.6942  71.6289  0.8804  0.7981  0.6444\n",
      "7     43.0817  5214.1554  72.2091  0.8810  0.7576  0.5662\n",
      "8     39.6486  4465.5613  66.8249  0.9020  0.7325  0.6519\n",
      "9     46.9510  6047.1012  77.7631  0.8755  0.7115  0.5046\n",
      "Mean  43.3122  5285.7943  72.6150  0.8845  0.7420  0.6026\n",
      "Std    2.1816   518.2565   3.5856  0.0122  0.0264  0.0728\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing:   0%|          | 0/7 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 10 candidates, totalling 100 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                          \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).\n",
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     46.2881  5787.1802  76.0735  0.8842  0.7403  0.5913\n",
      "1     43.0764  5342.3431  73.0913  0.8855  0.7323  0.6094\n",
      "2     44.6561  5677.5530  75.3495  0.8634  0.7375  0.6668\n",
      "3     41.6807  5041.4277  71.0030  0.8894  0.7235  0.7204\n",
      "4     47.6342  6582.2679  81.1312  0.8555  0.6918  0.5339\n",
      "5     46.2027  6325.2109  79.5312  0.8695  0.7146  0.6109\n",
      "6     44.7822  5713.0811  75.5849  0.8668  0.7623  0.5954\n",
      "7     46.2069  5930.6986  77.0110  0.8646  0.7654  0.6202\n",
      "8     41.8287  4953.9443  70.3843  0.8913  0.7081  0.6382\n",
      "9     48.3897  6429.6127  80.1849  0.8677  0.6815  0.4832\n",
      "Mean  45.0746  5778.3319  75.9345  0.8738  0.7257  0.6070\n",
      "Std    2.1881   531.0361   3.5051  0.0119  0.0262  0.0622\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                         \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          MAE        MSE     RMSE      R2   RMSLE    MAPE\n",
      "Fold                                                     \n",
      "0     44.9221  5301.7843  72.8134  0.8939  0.7528  0.5970\n",
      "1     40.0711  4503.2584  67.1063  0.9035  0.7200  0.6229\n",
      "2     42.4739  5516.8753  74.2757  0.8673  0.7358  0.6013\n",
      "3     41.0778  4883.7824  69.8841  0.8928  0.7536  0.7714\n",
      "4     46.5148  6291.5225  79.3191  0.8619  0.6813  0.5326\n",
      "5     44.2256  5677.7184  75.3506  0.8829  0.7144  0.5807\n",
      "6     42.6061  5068.9049  71.1962  0.8818  0.7875  0.6730\n",
      "7     43.7084  5191.2231  72.0501  0.8815  0.7590  0.6105\n",
      "8     40.2895  4495.9639  67.0519  0.9014  0.7343  0.6919\n",
      "9     47.4692  6096.7885  78.0819  0.8745  0.6726  0.5022\n",
      "Mean  43.3358  5302.7822  72.7129  0.8841  0.7311  0.6184\n",
      "Std    2.3864   576.8333   3.9510  0.0132  0.0336  0.0741\n",
      "Transformation Pipeline and Model Successfully Saved\n"
     ]
    }
   ],
   "source": [
    "# LightGBM training and predictions\n",
    "for loc in locations:\n",
    "\n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "    \n",
    "    # Calling preprocessing\n",
    "    train, test, is_day_feature = preprocessing(train, X_train_observed, X_train_estimated, X_test_estimated)\n",
    "   \n",
    "    targets = pd.DataFrame( {'pv_measurement': train['pv_measurement']})\n",
    "    X_train = train.drop(columns=['date_forecast','pv_measurement'])\n",
    "    X_train = feature_engineering(X_train)\n",
    "    X_test = test.drop(columns=['date_forecast'])\n",
    "    X_test = feature_engineering(X_test)\n",
    "    \n",
    "    # Training and prediction for diffrent seeds\n",
    "    total_predictions_light = None\n",
    "    seeds = [42,123]\n",
    "    for seed in seeds: \n",
    "        final_model_lGBM_e = process_location(X_train, targets, loc, seed)\n",
    "        predictions_lGBM_e = predict_model(final_model_lGBM_e, data=X_test)\n",
    "        final_predictions_lGBM_e = predictions_lGBM_e['prediction_label']\n",
    "        if total_predictions_light is None:\n",
    "            total_predictions_light = np.zeros_like(final_predictions_lGBM_e)\n",
    "        total_predictions_light += final_predictions_lGBM_e\n",
    "\n",
    "    mean_pred_light = total_predictions_light/len(seeds)\n",
    "\n",
    "    # Multiplying the predictions with is_day, so setting predictions at night to zero\n",
    "    adjusted_final_predictions_lGBM_e = mean_pred_light * is_day_feature['is_day:idx']\n",
    "\n",
    "    # Setting negative predictions to zero\n",
    "    adjusted_final_predictions_lGBM_e = np.clip(adjusted_final_predictions_lGBM_e, 0, None)\n",
    "\n",
    "    # Appening predictions for each location to final list\n",
    "    all_predictions_lGBM_e.append([adjusted_final_predictions_lGBM_e])\n",
    "\n",
    "# Changing final list to array\n",
    "all_predictions_lGBM_e = np.array(all_predictions_lGBM_e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = ['dew_or_rime:idx' ,'is_in_shadow:idx']\n",
    "cat_params = { 'A': {\n",
    "                        \"iterations\": 5000,\n",
    "                        \"learning_rate\": 0.034867396508006264,\n",
    "                        \"depth\": 8,\n",
    "                        \"l2_leaf_reg\": 1,\n",
    "                        \"loss_function\": \"MAE\",\n",
    "                        \"border_count\": 92,\n",
    "                        \"verbose\": 500,\n",
    "                        \"subsample\": 0.7641850606486046,\n",
    "                        'early_stopping_rounds': 100,\n",
    "                        'cat_features': cat_features,\n",
    "                        'random_state': 42, \n",
    "                    },\n",
    "              'B': {\n",
    "                        \"iterations\": 5000,\n",
    "                        \"learning_rate\": 0.037511244177544326,\n",
    "                        \"depth\": 6,\n",
    "                        \"l2_leaf_reg\": 5,\n",
    "                        \"loss_function\": \"MAE\",\n",
    "                        \"border_count\": 128,\n",
    "                        \"verbose\": 500,\n",
    "                        \"subsample\": 0.8012204629505595,\n",
    "                        'early_stopping_rounds': 100,\n",
    "                        'cat_features': cat_features,\n",
    "                        'random_state': 42, \n",
    "                    },\n",
    "              'C': {\"iterations\": 5000, \n",
    "                    \"learning_rate\": 0.03425599789981457,\n",
    "                    \"depth\": 8,\n",
    "                    \"l2_leaf_reg\": 4,\n",
    "                    \"loss_function\": \"MAE\", \n",
    "                    \"border_count\": 218, \n",
    "                    \"verbose\": 500, \n",
    "                    \"subsample\": 0.6848272280307022, \n",
    "                    'early_stopping_rounds': 100,\n",
    "                    'cat_features': cat_features,\n",
    "                    'random_state': 42, }\n",
    "}\n",
    "              \n",
    "cat_params_no_feature =  { 'A': {\n",
    "                        \"iterations\": 5000,\n",
    "                        \"learning_rate\": 0.034867396508006264,\n",
    "                        \"depth\": 8,\n",
    "                        \"l2_leaf_reg\": 1,\n",
    "                        \"loss_function\": \"MAE\",\n",
    "                        \"border_count\": 92,\n",
    "                        \"verbose\": 500,\n",
    "                        \"subsample\": 0.7641850606486046,\n",
    "                        'early_stopping_rounds': 100,\n",
    "                        'random_state': 42, \n",
    "                    },\n",
    "              'B': {\n",
    "                        \"iterations\": 5000,\n",
    "                        \"learning_rate\": 0.037511244177544326,\n",
    "                        \"depth\": 6,\n",
    "                        \"l2_leaf_reg\": 5,\n",
    "                        \"loss_function\": \"MAE\",\n",
    "                        \"border_count\": 128,\n",
    "                        \"verbose\": 500,\n",
    "                        \"subsample\": 0.8012204629505595,\n",
    "                        'early_stopping_rounds': 100,\n",
    "                        'random_state': 42, \n",
    "                    },\n",
    "              'C': {\"iterations\": 5000, \n",
    "                    \"learning_rate\": 0.03425599789981457,\n",
    "                    \"depth\": 8,\n",
    "                    \"l2_leaf_reg\": 4,\n",
    "                    \"loss_function\": \"MAE\", \n",
    "                    \"border_count\": 218, \n",
    "                    \"verbose\": 500, \n",
    "                    \"subsample\": 0.6848272280307022, \n",
    "                    'early_stopping_rounds': 100,\n",
    "                    'random_state': 42, }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CATegorical(df):\n",
    "    df['dew_or_rime:idx'] = df['dew_or_rime:idx'].astype(int)\n",
    "    df['is_in_shadow:idx'] = df['is_in_shadow:idx'].astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing... A\n",
      "0:\tlearn: 1136.5478294\ttest: 1126.7779256\tbest: 1126.7779256 (0)\ttotal: 132ms\tremaining: 10m 59s\n",
      "500:\tlearn: 299.1589179\ttest: 339.1212844\tbest: 339.1091885 (498)\ttotal: 47s\tremaining: 7m 1s\n",
      "1000:\tlearn: 246.7139268\ttest: 328.1777351\tbest: 328.1777351 (1000)\ttotal: 1m 25s\tremaining: 5m 42s\n",
      "1500:\tlearn: 215.3908163\ttest: 322.7291723\tbest: 322.7291723 (1500)\ttotal: 2m 6s\tremaining: 4m 54s\n",
      "2000:\tlearn: 194.1990833\ttest: 320.5482988\tbest: 320.5151028 (1999)\ttotal: 2m 56s\tremaining: 4m 23s\n",
      "2500:\tlearn: 177.6811755\ttest: 319.1596178\tbest: 319.1576476 (2499)\ttotal: 3m 47s\tremaining: 3m 47s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 318.7575341\n",
      "bestIteration = 2575\n",
      "\n",
      "Shrink model to first 2576 iterations.\n",
      "Doing... B\n",
      "0:\tlearn: 228.6978029\ttest: 226.7140601\tbest: 226.7140601 (0)\ttotal: 58.1ms\tremaining: 4m 50s\n",
      "500:\tlearn: 58.1835306\ttest: 71.3786610\tbest: 71.3786610 (500)\ttotal: 36.3s\tremaining: 5m 26s\n",
      "1000:\tlearn: 50.8143242\ttest: 69.1515526\tbest: 69.1496800 (997)\ttotal: 1m 11s\tremaining: 4m 45s\n",
      "1500:\tlearn: 46.1937466\ttest: 67.7542100\tbest: 67.7464708 (1497)\ttotal: 1m 48s\tremaining: 4m 12s\n",
      "2000:\tlearn: 42.9269169\ttest: 66.9238065\tbest: 66.9238065 (2000)\ttotal: 2m 22s\tremaining: 3m 33s\n",
      "2500:\tlearn: 40.4953390\ttest: 66.5922923\tbest: 66.5694436 (2462)\ttotal: 2m 59s\tremaining: 2m 59s\n",
      "3000:\tlearn: 38.4702138\ttest: 66.1495129\tbest: 66.1495129 (3000)\ttotal: 3m 35s\tremaining: 2m 23s\n",
      "3500:\tlearn: 36.7447019\ttest: 65.8055635\tbest: 65.8055635 (3500)\ttotal: 4m 10s\tremaining: 1m 47s\n",
      "4000:\tlearn: 35.2553826\ttest: 65.6623681\tbest: 65.6502307 (3996)\ttotal: 4m 48s\tremaining: 1m 11s\n",
      "4500:\tlearn: 34.0334180\ttest: 65.5279330\tbest: 65.5173217 (4472)\ttotal: 5m 24s\tremaining: 36s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 65.36752104\n",
      "bestIteration = 4677\n",
      "\n",
      "Shrink model to first 4678 iterations.\n",
      "Doing... C\n",
      "0:\tlearn: 189.5805841\ttest: 186.9749290\tbest: 186.9749290 (0)\ttotal: 108ms\tremaining: 8m 58s\n",
      "500:\tlearn: 42.1601214\ttest: 53.8091103\tbest: 53.8091103 (500)\ttotal: 50.7s\tremaining: 7m 35s\n",
      "1000:\tlearn: 31.7544443\ttest: 50.9129920\tbest: 50.9129920 (1000)\ttotal: 1m 37s\tremaining: 6m 28s\n",
      "1500:\tlearn: 26.3855241\ttest: 49.5481197\tbest: 49.5481197 (1500)\ttotal: 2m 25s\tremaining: 5m 38s\n",
      "2000:\tlearn: 22.3745086\ttest: 48.6494355\tbest: 48.6429118 (1993)\ttotal: 3m 9s\tremaining: 4m 44s\n",
      "2500:\tlearn: 19.6157120\ttest: 48.2080926\tbest: 48.2079498 (2499)\ttotal: 3m 52s\tremaining: 3m 52s\n",
      "3000:\tlearn: 17.5156673\ttest: 47.8121118\tbest: 47.8109946 (2998)\ttotal: 4m 40s\tremaining: 3m 7s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 47.60896408\n",
      "bestIteration = 3361\n",
      "\n",
      "Shrink model to first 3362 iterations.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.impute import IterativeImputer\n",
    "all_predictions_cat = []\n",
    "# Cat_1 training and predictions\n",
    "for loc in locations:\n",
    "    \n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "\n",
    "    # Calling preprocessing\n",
    "    X_train_cat, X_test_cat, is_day_feature1 = preprocessing(train, X_train_observed, X_train_estimated, X_test_estimated,mode = 'cat')\n",
    "    X_train_cat.drop(columns=['date_forecast'], inplace=True)\n",
    "    print(f'Doing... {loc}')\n",
    "\n",
    "    imputer = IterativeImputer(max_iter=5, random_state=42)\n",
    "    for col in X_train_cat.columns:\n",
    "        X_train_cat[col] = imputer.fit_transform(np.array(X_train_cat[col]).reshape(-1,1))\n",
    "    for col in X_test_cat.columns:\n",
    "        X_test_cat[col] = imputer.fit_transform(np.array(X_test_cat[col]).reshape(-1,1))\n",
    "    \n",
    "    targets_cat = pd.DataFrame( {'pv_measurement': X_train_cat['pv_measurement']})\n",
    "    X_train_cat = X_train_cat.drop(columns=['pv_measurement'])\n",
    "    X_train_cat = CATegorical(X_train_cat)\n",
    "    X_test_cat = CATegorical(X_test_cat)\n",
    "\n",
    "    # Catboooooooozt fun\n",
    "    model_cat = CatBoostRegressor(**cat_params[loc])\n",
    "\n",
    "    X_train_cat1, X_val_cat1, y_train_cat1, y_val_cat1 = train_test_split(X_train_cat, targets_cat, test_size=0.2, random_state=42)\n",
    "    \n",
    "    # Training\n",
    "    model_cat.fit(X_train_cat1, y_train_cat1['pv_measurement'],eval_set=(X_val_cat1, y_val_cat1['pv_measurement']),)\n",
    "\n",
    "    # Prediction\n",
    "    predictions_cat = model_cat.predict(X_test_cat[model_cat.feature_names_])\n",
    "    \n",
    "    # Multiplying the predictions with is_day, so setting predictions at night to zero\n",
    "    adjusted_final_predictions_cat = predictions_cat * is_day_feature1['is_day:idx']\n",
    "\n",
    "    # Setting negative predictions to zero\n",
    "    adjusted_final_predictions_cat = np.clip(adjusted_final_predictions_cat, 0, None)\n",
    "\n",
    "    # Appening predictions for each location to final list\n",
    "    all_predictions_cat.append(adjusted_final_predictions_cat)\n",
    "\n",
    "# Changing final list to array\n",
    "all_predictions_cat = np.array(all_predictions_cat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 945.7421297\ttest: 925.3651966\tbest: 925.3651966 (0)\ttotal: 27.5ms\tremaining: 2m 17s\n",
      "500:\tlearn: 277.4531173\ttest: 301.6730739\tbest: 301.6730739 (500)\ttotal: 12.1s\tremaining: 1m 48s\n",
      "1000:\tlearn: 237.6336661\ttest: 288.8311718\tbest: 288.8311718 (1000)\ttotal: 23.2s\tremaining: 1m 32s\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\claxl\\Documents\\GitHub\\MLProject\\Definitiva\\145ISA3.ipynb Cella 17\u001b[0m line \u001b[0;36m3\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/claxl/Documents/GitHub/MLProject/Definitiva/145ISA3.ipynb#X22sZmlsZQ%3D%3D?line=35'>36</a>\u001b[0m X_train_cat_3, X_test_cat_3, y_train_cat_3, y_test_cat_3 \u001b[39m=\u001b[39m train_test_split(X_train_3, targets_3, test_size\u001b[39m=\u001b[39m\u001b[39m0.2\u001b[39m, random_state\u001b[39m=\u001b[39m\u001b[39m42\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/claxl/Documents/GitHub/MLProject/Definitiva/145ISA3.ipynb#X22sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m \u001b[39m# Train model\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/claxl/Documents/GitHub/MLProject/Definitiva/145ISA3.ipynb#X22sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m model_cat_3\u001b[39m.\u001b[39;49mfit(X_train_cat_3, y_train_cat_3[\u001b[39m'\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m'\u001b[39;49m],eval_set\u001b[39m=\u001b[39;49m(X_test_cat_3, y_test_cat_3[\u001b[39m'\u001b[39;49m\u001b[39mpv_measurement\u001b[39;49m\u001b[39m'\u001b[39;49m]),)  \n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/claxl/Documents/GitHub/MLProject/Definitiva/145ISA3.ipynb#X22sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# Pred\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/claxl/Documents/GitHub/MLProject/Definitiva/145ISA3.ipynb#X22sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m pred_cat_3 \u001b[39m=\u001b[39m model_cat_3\u001b[39m.\u001b[39mpredict(X_test_3[model_cat_3\u001b[39m.\u001b[39mfeature_names_])\n",
      "File \u001b[1;32mc:\\Users\\claxl\\anaconda3\\envs\\pycaret\\lib\\site-packages\\catboost\\core.py:5703\u001b[0m, in \u001b[0;36mCatBoostRegressor.fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, sample_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   5700\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m \u001b[39min\u001b[39;00m params:\n\u001b[0;32m   5701\u001b[0m     CatBoostRegressor\u001b[39m.\u001b[39m_check_is_compatible_loss(params[\u001b[39m'\u001b[39m\u001b[39mloss_function\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m-> 5703\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit(X, y, cat_features, text_features, embedding_features, \u001b[39mNone\u001b[39;49;00m, sample_weight, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, baseline,\n\u001b[0;32m   5704\u001b[0m                  use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description,\n\u001b[0;32m   5705\u001b[0m                  verbose_eval, metric_period, silent, early_stopping_rounds,\n\u001b[0;32m   5706\u001b[0m                  save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\n",
      "File \u001b[1;32mc:\\Users\\claxl\\anaconda3\\envs\\pycaret\\lib\\site-packages\\catboost\\core.py:2319\u001b[0m, in \u001b[0;36mCatBoost._fit\u001b[1;34m(self, X, y, cat_features, text_features, embedding_features, pairs, sample_weight, group_id, group_weight, subgroup_id, pairs_weight, baseline, use_best_model, eval_set, verbose, logging_level, plot, plot_file, column_description, verbose_eval, metric_period, silent, early_stopping_rounds, save_snapshot, snapshot_file, snapshot_interval, init_model, callbacks, log_cout, log_cerr)\u001b[0m\n\u001b[0;32m   2315\u001b[0m allow_clear_pool \u001b[39m=\u001b[39m train_params[\u001b[39m\"\u001b[39m\u001b[39mallow_clear_pool\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m   2317\u001b[0m \u001b[39mwith\u001b[39;00m log_fixup(log_cout, log_cerr), \\\n\u001b[0;32m   2318\u001b[0m     plot_wrapper(plot, plot_file, \u001b[39m'\u001b[39m\u001b[39mTraining plots\u001b[39m\u001b[39m'\u001b[39m, [_get_train_dir(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_params())]):\n\u001b[1;32m-> 2319\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train(\n\u001b[0;32m   2320\u001b[0m         train_pool,\n\u001b[0;32m   2321\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39meval_sets\u001b[39;49m\u001b[39m\"\u001b[39;49m],\n\u001b[0;32m   2322\u001b[0m         params,\n\u001b[0;32m   2323\u001b[0m         allow_clear_pool,\n\u001b[0;32m   2324\u001b[0m         train_params[\u001b[39m\"\u001b[39;49m\u001b[39minit_model\u001b[39;49m\u001b[39m\"\u001b[39;49m]\n\u001b[0;32m   2325\u001b[0m     )\n\u001b[0;32m   2327\u001b[0m \u001b[39m# Have property feature_importance possibly set\u001b[39;00m\n\u001b[0;32m   2328\u001b[0m loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_object\u001b[39m.\u001b[39m_get_loss_function_name()\n",
      "File \u001b[1;32mc:\\Users\\claxl\\anaconda3\\envs\\pycaret\\lib\\site-packages\\catboost\\core.py:1723\u001b[0m, in \u001b[0;36m_CatBoostBase._train\u001b[1;34m(self, train_pool, test_pool, params, allow_clear_pool, init_model)\u001b[0m\n\u001b[0;32m   1722\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_train\u001b[39m(\u001b[39mself\u001b[39m, train_pool, test_pool, params, allow_clear_pool, init_model):\n\u001b[1;32m-> 1723\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_object\u001b[39m.\u001b[39;49m_train(train_pool, test_pool, params, allow_clear_pool, init_model\u001b[39m.\u001b[39;49m_object \u001b[39mif\u001b[39;49;00m init_model \u001b[39melse\u001b[39;49;00m \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m   1724\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_set_trained_model_attributes()\n",
      "File \u001b[1;32m_catboost.pyx:4645\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32m_catboost.pyx:4694\u001b[0m, in \u001b[0;36m_catboost._CatBoost._train\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Catboost nr 3\n",
    "all_predictions_cat_2 = []\n",
    "for loc in locations:\n",
    "    \n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "\n",
    "    X_train_3, X_test_3, is_day_feature_3 = preprocessing(train, X_train_observed, X_train_estimated, X_test_estimated)\n",
    "    X_train_3.drop(columns=['date_forecast'], inplace=True)\n",
    "    imputer = IterativeImputer(max_iter=5, random_state=42)\n",
    "    for col in X_train_3.columns:\n",
    "        X_train_3[col] = imputer.fit_transform(np.array(X_train_3[col]).reshape(-1,1))\n",
    "    for col in X_test_3.columns:\n",
    "        X_test_3[col] = imputer.fit_transform(np.array(X_test_3[col]).reshape(-1,1))\n",
    "    targets_3 = pd.DataFrame( {'pv_measurement': X_train_3['pv_measurement']})\n",
    "    X_train_3 = X_train_3.drop(columns=['pv_measurement'])\n",
    "    \n",
    "    model_cat_3 = CatBoostRegressor(**cat_params_no_feature[loc])\n",
    "    X_train_3 = feature_engineering(X_train_3)\n",
    "    X_test_3 = feature_engineering(X_test_3)\n",
    "\n",
    "    # Create 'sin_sun_azimuth' and 'cos_sun_azimuth' from 'sun_azimuth' in radians\n",
    "    X_train_3['sin_sun_azimuth'] = np.sin(np.radians(X_train_3['sun_azimuth:d']))\n",
    "    X_train_3['cos_sun_azimuth'] = np.cos(np.radians(X_train_3['sun_azimuth:d']))\n",
    "    X_test_3['sin_sun_azimuth'] = np.sin(np.radians(X_test_3['sun_azimuth:d']))\n",
    "    X_test_3['cos_sun_azimuth'] = np.cos(np.radians(X_test_3['sun_azimuth:d']))\n",
    "\n",
    "    # Now drop the original 'sun_azimuth' feature\n",
    "    X_train_3.drop('sun_azimuth:d', axis=1, inplace=True)\n",
    "    X_test_3.drop('sun_azimuth:d', axis=1, inplace=True)\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train_cat_3, X_test_cat_3, y_train_cat_3, y_test_cat_3 = train_test_split(X_train_3, targets_3, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    model_cat_3.fit(X_train_cat_3, y_train_cat_3['pv_measurement'],eval_set=(X_test_cat_3, y_test_cat_3['pv_measurement']),)  \n",
    "    \n",
    "    # Pred\n",
    "    pred_cat_3 = model_cat_3.predict(X_test_3[model_cat_3.feature_names_])\n",
    "\n",
    "    # Multiplying the predictions with is_day, so setting predictions at night to zero\n",
    "    adjusted_final_predictions_cat_3 = pred_cat_3 * is_day_feature_3['is_day:idx']\n",
    "\n",
    "    # Setting negative predictions to zero\n",
    "    adjusted_final_predictions_cat_3 = np.clip(adjusted_final_predictions_cat_3, 0, None)\n",
    "\n",
    "    # Appening predictions for each location to final list\n",
    "    all_predictions_cat_2.append(adjusted_final_predictions_cat_3) \n",
    "\n",
    "# Changing final list to array   \n",
    "all_predictions_cat_2 = np.array(all_predictions_cat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 944.5035972\ttest: 923.1513579\tbest: 923.1513579 (0)\ttotal: 18.8ms\tremaining: 1m 33s\n",
      "500:\tlearn: 281.9614880\ttest: 305.9260216\tbest: 305.9260216 (500)\ttotal: 7.8s\tremaining: 1m 10s\n",
      "1000:\tlearn: 246.4577566\ttest: 294.1713330\tbest: 294.1713330 (1000)\ttotal: 15.4s\tremaining: 1m 1s\n",
      "1500:\tlearn: 224.1178152\ttest: 289.0675935\tbest: 289.0675935 (1500)\ttotal: 23.7s\tremaining: 55.3s\n",
      "2000:\tlearn: 209.1595791\ttest: 286.2417621\tbest: 286.2407106 (1999)\ttotal: 32.8s\tremaining: 49.2s\n",
      "2500:\tlearn: 196.4720114\ttest: 283.7446587\tbest: 283.7254983 (2498)\ttotal: 41.1s\tremaining: 41.1s\n",
      "3000:\tlearn: 185.7360923\ttest: 282.4002288\tbest: 282.3837594 (2984)\ttotal: 49.3s\tremaining: 32.9s\n",
      "3500:\tlearn: 177.7502660\ttest: 281.3517613\tbest: 281.3517613 (3500)\ttotal: 1m\tremaining: 25.8s\n",
      "4000:\tlearn: 171.3214326\ttest: 280.0675958\tbest: 280.0675958 (4000)\ttotal: 1m 10s\tremaining: 17.5s\n",
      "4500:\tlearn: 165.6843097\ttest: 279.3612567\tbest: 279.3253236 (4483)\ttotal: 1m 20s\tremaining: 8.94s\n",
      "4999:\tlearn: 160.8614180\ttest: 278.8415532\tbest: 278.8413677 (4997)\ttotal: 1m 30s\tremaining: 0us\n",
      "\n",
      "bestTest = 278.8413677\n",
      "bestIteration = 4997\n",
      "\n",
      "Shrink model to first 4998 iterations.\n",
      "0:\tlearn: 176.2064924\ttest: 178.0666740\tbest: 178.0666740 (0)\ttotal: 11.5ms\tremaining: 57.7s\n",
      "500:\tlearn: 48.1845857\ttest: 51.0394255\tbest: 51.0394255 (500)\ttotal: 4.99s\tremaining: 44.8s\n",
      "1000:\tlearn: 43.6771411\ttest: 49.1602602\tbest: 49.1602602 (1000)\ttotal: 9.46s\tremaining: 37.8s\n",
      "1500:\tlearn: 40.8908581\ttest: 48.1432478\tbest: 48.1432478 (1500)\ttotal: 13.9s\tremaining: 32.5s\n",
      "2000:\tlearn: 38.7785557\ttest: 47.4222769\tbest: 47.4222769 (2000)\ttotal: 19.2s\tremaining: 28.8s\n",
      "2500:\tlearn: 37.2041698\ttest: 47.0157070\tbest: 47.0145888 (2497)\ttotal: 24s\tremaining: 24s\n",
      "3000:\tlearn: 36.1351843\ttest: 46.7122752\tbest: 46.7108663 (2977)\ttotal: 28.6s\tremaining: 19.1s\n",
      "3500:\tlearn: 35.1666700\ttest: 46.5220665\tbest: 46.5204756 (3499)\ttotal: 33.1s\tremaining: 14.2s\n",
      "4000:\tlearn: 34.1818714\ttest: 46.3151200\tbest: 46.3135503 (3991)\ttotal: 37.5s\tremaining: 9.37s\n",
      "4500:\tlearn: 33.2539689\ttest: 46.1747535\tbest: 46.1666022 (4487)\ttotal: 42s\tremaining: 4.66s\n",
      "4999:\tlearn: 32.5576572\ttest: 46.0466781\tbest: 46.0420013 (4983)\ttotal: 46.5s\tremaining: 0us\n",
      "\n",
      "bestTest = 46.04200129\n",
      "bestIteration = 4983\n",
      "\n",
      "Shrink model to first 4984 iterations.\n",
      "0:\tlearn: 148.5076519\ttest: 147.6022943\tbest: 147.6022943 (0)\ttotal: 25ms\tremaining: 2m 5s\n",
      "500:\tlearn: 36.8515377\ttest: 43.4261647\tbest: 43.4261647 (500)\ttotal: 9.24s\tremaining: 1m 22s\n",
      "1000:\tlearn: 29.7675889\ttest: 41.6958990\tbest: 41.6958990 (1000)\ttotal: 19.9s\tremaining: 1m 19s\n",
      "1500:\tlearn: 25.7381729\ttest: 40.8439695\tbest: 40.8417779 (1495)\ttotal: 30.4s\tremaining: 1m 10s\n",
      "2000:\tlearn: 22.9784635\ttest: 40.3558991\tbest: 40.3504795 (1989)\ttotal: 40s\tremaining: 1m\n",
      "2500:\tlearn: 21.0048664\ttest: 40.0273358\tbest: 40.0258456 (2491)\ttotal: 49.4s\tremaining: 49.4s\n",
      "3000:\tlearn: 19.4466818\ttest: 39.7665792\tbest: 39.7653385 (2982)\ttotal: 59.2s\tremaining: 39.4s\n",
      "3500:\tlearn: 17.9613694\ttest: 39.5627412\tbest: 39.5586776 (3478)\ttotal: 1m 9s\tremaining: 29.6s\n",
      "Stopped by overfitting detector  (100 iterations wait)\n",
      "\n",
      "bestTest = 39.45672039\n",
      "bestIteration = 3872\n",
      "\n",
      "Shrink model to first 3873 iterations.\n"
     ]
    }
   ],
   "source": [
    "all_predictions_cat_3 = []\n",
    "# Catboost nr 3\n",
    "for loc in locations:\n",
    "    \n",
    "    # Load your data\n",
    "    train = pd.read_parquet(f'{loc}/train_targets.parquet').fillna(0)\n",
    "    X_train_estimated = pd.read_parquet(f'{loc}/X_train_estimated.parquet')\n",
    "    X_train_observed = pd.read_parquet(f'{loc}/X_train_observed.parquet')\n",
    "    X_test_estimated = pd.read_parquet(f'{loc}/X_test_estimated.parquet')\n",
    "\n",
    "    X_train_3, X_test_3, is_day_feature_3 = preprocessing(train, X_train_observed, X_train_estimated, X_test_estimated,mode = 'catboost')\n",
    "    X_train_3.drop(columns=['date_forecast'], inplace=True)\n",
    "    imputer = IterativeImputer(max_iter=5, random_state=42)\n",
    "    for col in X_train_3.columns:\n",
    "        X_train_3[col] = imputer.fit_transform(np.array(X_train_3[col]).reshape(-1,1))\n",
    "    for col in X_test_3.columns:\n",
    "        X_test_3[col] = imputer.fit_transform(np.array(X_test_3[col]).reshape(-1,1))\n",
    "    targets_3 = pd.DataFrame( {'pv_measurement': X_train_3['pv_measurement']})\n",
    "    X_train_3 = X_train_3.drop(columns=['pv_measurement'])\n",
    "    \n",
    "    model_cat_3 = CatBoostRegressor(**cat_params_no_feature[loc])\n",
    "   # X_train_3 = feature_engineering(X_train_3)\n",
    "   # X_test_3 = feature_engineering(X_test_3)\n",
    "\n",
    "    # Create 'sin_sun_azimuth' and 'cos_sun_azimuth' from 'sun_azimuth' in radians\n",
    "    X_train_3['sin_sun_azimuth'] = np.sin(np.radians(X_train_3['sun_azimuth:d']))\n",
    "    X_train_3['cos_sun_azimuth'] = np.cos(np.radians(X_train_3['sun_azimuth:d']))\n",
    "    X_test_3['sin_sun_azimuth'] = np.sin(np.radians(X_test_3['sun_azimuth:d']))\n",
    "    X_test_3['cos_sun_azimuth'] = np.cos(np.radians(X_test_3['sun_azimuth:d']))\n",
    "\n",
    "    # Now drop the original 'sun_azimuth' feature\n",
    "    X_train_3.drop('sun_azimuth:d', axis=1, inplace=True)\n",
    "    X_test_3.drop('sun_azimuth:d', axis=1, inplace=True)\n",
    "\n",
    "    # Split the training data into training and validation sets\n",
    "    X_train_cat_3, X_test_cat_3, y_train_cat_3, y_test_cat_3 = train_test_split(X_train_3, targets_3, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Train model\n",
    "    model_cat_3.fit(X_train_cat_3, y_train_cat_3['pv_measurement'],eval_set=(X_test_cat_3, y_test_cat_3['pv_measurement']),)  \n",
    "    \n",
    "    # Pred\n",
    "    pred_cat_3 = model_cat_3.predict(X_test_3[model_cat_3.feature_names_])\n",
    "\n",
    "    # Multiplying the predictions with is_day, so setting predictions at night to zero\n",
    "    adjusted_final_predictions_cat_3 = pred_cat_3 * is_day_feature_3['is_day:idx']\n",
    "\n",
    "    # Setting negative predictions to zero\n",
    "    adjusted_final_predictions_cat_3 = np.clip(adjusted_final_predictions_cat_3, 0, None)\n",
    "\n",
    "    # Appening predictions for each location to final list\n",
    "    all_predictions_cat_3.append(adjusted_final_predictions_cat_3) \n",
    "\n",
    "# Changing final list to array   \n",
    "all_predictions_cat_3 = np.array(all_predictions_cat_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3, 720)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_predictions_cat_2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2160,)\n"
     ]
    }
   ],
   "source": [
    "all_predictions_lGBM_e = np.array(all_predictions_lGBM_e).flatten()\n",
    "all_predictions_cat = np.array(all_predictions_cat).flatten()\n",
    "all_predictions_cat_2 = np.array(all_predictions_cat_2).flatten()\n",
    "all_predictions_cat_3 = np.array(all_predictions_cat_3).flatten()\n",
    "all_pred = 0.25*all_predictions_cat+0.25 * all_predictions_lGBM_e+0.25*all_predictions_cat_2 + 0.25*all_predictions_cat_3\n",
    "print(all_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "final_predictions = all_pred\n",
    "\n",
    "# Save the final_predictions to CSV\n",
    "df = pd.DataFrame(final_predictions, columns=['prediction'])\n",
    "df['id'] = df.index\n",
    "df = df[['id', 'prediction']]\n",
    "df.to_csv('submit1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = read_csv('submit.csv')\n",
    "df1 = pd.read_csv('best_score1.csv')\n",
    "df2 = pd.read_csv('best_score2.csv')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# plot delle differenze tra df e df1\n",
    "plt.plot(df1['prediction'] - df['prediction'])\n",
    "plt.title('Differenze tra df1 e df')\n",
    "plt.xlabel('Indice')\n",
    "plt.ylabel('Differenza')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "display-name",
   "language": "python",
   "name": "pycaret"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
